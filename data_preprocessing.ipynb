{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "UJwzCNVpC6_b"
   },
   "source": [
    "# Identifying Deepfake Videos with Convolutional Neural Networks"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Our team initially worked on colab to extract random frames from videos, and extract faces from those videos. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### i. Extract Random Frames and Labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "YbkfhzIL0SR7"
   },
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import cv2 as cv    # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "import seaborn as sns\n",
    "import os\n",
    "import random"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Our data was first hosted on google drive, and mounted for colab \n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "DATA_FOLDER = '/content/drive/My Drive/Summer 2020/CS542 Deepfake Project/data/'\n",
    "TRAIN_SAMPLE_FOLDER = 'dfdc_train_part_47'\n",
    "#TEST_FOLDER = 'test_videos'\n",
    "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_list = list(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))\n",
    "train_list.remove('metadata.json')       #remove metadata file from video list \n",
    "len(train_list)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The metadata file contains the labels we need to create npy for the frames we extract\n",
    "def get_meta_from_json(path):\n",
    "    df = pd.read_json(os.path.join(DATA_FOLDER, path, 'metadata.json'))\n",
    "    df = df.T\n",
    "    return df\n",
    "\n",
    "meta_train_df = get_meta_from_json(TRAIN_SAMPLE_FOLDER)\n",
    "meta_train_df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#The function takes in a list of strings that represent videos, \n",
    "#and add random frames and their corresponding labels to two global lists \n",
    "def images_from_video(train_list):\n",
    "  for n in range(len(train_list)):\n",
    "    video_path = os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER, train_list[n])\n",
    "    capture_image = cv.VideoCapture(video_path) \n",
    "    count = 5\n",
    "    while count>0:\n",
    "      frames=random.randint(1,50)\n",
    "      capture_image.set(1,frames)\n",
    "      ret, frame = capture_image.read()\n",
    "      if ret == False:\n",
    "        continue #go to the beginning of the while loop\n",
    "      label = meta_train_df.loc[video_path.split(\"/\")[-1]].label\n",
    "      train_labels.append(label)\n",
    "      train_images.append(frame)\n",
    "      count -= 1\n",
    "  return None"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Each data folder was larger and it was not possible to fit all frames into one numpy array per folder\n",
    "#Here we break the entire video list into chunks for easier manipulation\n",
    "chunks = [train_list[x:x+101] for x in range(0, len(train_list), 101)] #break the list of videos into batches"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each chunk, we perform frame extraction and create image and label npy files \n",
    "for c in range(len(chunks)):\n",
    "  train_images = []\n",
    "  train_labels = []\n",
    "  images_from_video(chunks[c])\n",
    "  t_i =np.asarray(train_images)\n",
    "  t_l =np.asarray(train_labels)\n",
    "  np.save(os.path.join(DATA_FOLDER,  \"npy\",'train_images_47_'+str(c)+'.npy'), t_i) #saving the file in a folder \"npy\" in the data folder\n",
    "  np.save(os.path.join(DATA_FOLDER,  \"npy\",'train_labels_47_'+str(c)+'.npy'), t_l) #change the '47' to the folder you are processing\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ii. Extract faces"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Taking a few frames from each video still produced sizable data that was difficult computationally and for data transfer. We decided to extract faces from the frames, since most of the background would not present any artifacts of the GANs. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import tensorflow as tf\n",
    "from tensorflow.keras import datasets, layers, models\n",
    "import matplotlib.pyplot as plt    # for plotting the images\n",
    "%matplotlib inline\n",
    "import cv2 as cv    # for capturing videos\n",
    "import math   # for mathematical operations\n",
    "import pandas as pd\n",
    "from keras.preprocessing import image   # for preprocessing the images\n",
    "import numpy as np    # for mathematical operations\n",
    "from keras.utils import np_utils\n",
    "from skimage.transform import resize   # for resizing images\n",
    "import seaborn as sns\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For working on google drive\n",
    "from google.colab import drive\n",
    "drive.mount('/content/drive')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Path to the npy that we have created in the last part of the code\n",
    "NPY_FOLDER = '/content/drive/My Drive/Summer 2020/CS542 Deepfake Project/data/npy'\n",
    "#TRAIN_SAMPLE_FOLDER = 'dfdc_train_part_47'\n",
    "#TEST_FOLDER = 'test_videos'\n",
    "print(f\"Train samples: {len(os.listdir(os.path.join(DATA_FOLDER, TRAIN_SAMPLE_FOLDER)))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "UqdQzrRi_IbB"
   },
   "outputs": [],
   "source": [
    "#Install and import the module for face extraction \n",
    "pip install git+https://github.com/rcmalli/keras-vggface.git\n",
    "pip install mtcnn\n",
    "import mtcnn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Wn7efOe5_b8s"
   },
   "outputs": [],
   "source": [
    "detector = mtcnn.MTCNN()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "NxW78t___xuP"
   },
   "source": [
    "Here is an sample output of the face extractor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "[{'box': [525, 510, 129, 163],       \\\n",
    "  'confidence': 0.9989194869995117, \\\n",
    "  'keypoints': {'left_eye': (557, 569),\\\n",
    "   'mouth_left': (554, 635),\\\n",
    "   'mouth_right': (604, 639),\\\n",
    "   'nose': (577, 597),\\\n",
    "   'right_eye': (617, 574)}}]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "GLOWChcB_1x5"
   },
   "outputs": [],
   "source": [
    "# A function which takes an image as numpy array and outputs the face as numpy array, or an empty list if it can't find a face\n",
    "def face_extraxtor(frame):\n",
    "  results = detector.detect_faces(frame)\n",
    "  if not results:\n",
    "    return []\n",
    "  else:\n",
    "    x1, y1, width, height = results[0]['box']\n",
    "    x2, y2 = x1 + width, y1 + height\n",
    "    return frame[y1:y2, x1:x2]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "b9n7BtuZ_2c-"
   },
   "outputs": [],
   "source": [
    "# Cycle through each chunk of saved data, extract the faces, and save them to a numpy file along with the corresponding label\n",
    "for I in range(37):\n",
    "  chunk_dat = np.load(os.path.join('/content/drive/My Drive/Machine Learning/Deepfakes/folder_13/npy_13/train_images_13_'+str(I)+'.npy'),allow_pickle=True)\n",
    "  chunk_lab = np.load(os.path.join('/content/drive/My Drive/Machine Learning/Deepfakes/folder_13/npy_13/train_labels_13_'+str(I)+'.npy'))\n",
    "  face_set = []\n",
    "  label_set = []\n",
    "  for c in range(len(chunk_dat)):\n",
    "    face = face_extraxtor(chunk_dat[c])\n",
    "    if len(face) != 0:\n",
    "      face = cv.resize(face,(252,252),interpolation=cv.INTER_AREA)\n",
    "      face_set += [face]\n",
    "      if chunk_lab[c] == 'REAL':\n",
    "          label_set += [float(1)]\n",
    "      elif chunk_lab[c] == 'FAKE':\n",
    "          label_set += [float(0)]\n",
    "  face_set = np.asarray(face_set)/255\n",
    "  label_set = np.asarray(label_set)\n",
    "  np.save(os.path.join('/content/drive/My Drive/Machine Learning/Deepfakes/folder_13/faces_13/tr_faces_13_'+str(I)+'.npy'), face_set)\n",
    "  np.save(os.path.join('/content/drive/My Drive/Machine Learning/Deepfakes/folder_13/faces_13/tr_labs_13_'+str(I)+'.npy'), label_set)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "FcaR_iZJEUtT"
   },
   "source": [
    "Note that the above code only loads data from one folder. We ran this code repeatedly on different machines to maximize the size of our dataset. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "ks85mBaP_302"
   },
   "source": [
    "### iii. Balancing the Data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "colab_type": "text",
    "id": "1j9_cfPNF9YD"
   },
   "source": [
    "We uploaded the face and label npy arrays to SCC, and we balanced the data evenly between reals and fakes, shuffled their order, and then randomly divided them into folders MIX_1 MIX_2 and MIX_3 in roughly a 70-15-15 ratio, to be used as the training, validation and test sets respectively."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "Ts1W5MW3F837"
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np    \n",
    "import os\n",
    "import random\n",
    "from keras.preprocessing.image import save_img\n",
    "import cv2 "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "colab": {},
    "colab_type": "code",
    "id": "8WqrPwStCQw9"
   },
   "outputs": [],
   "source": [
    "dataset = 47 #folder number        27        13       47\n",
    "chunks = 24 #number of chunks      24        36       24"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "face_FOLDER = 'data/dfdc_'+str(dataset)\n",
    "DATA_FOLDER = 'data'\n",
    "print(f\"face npy: {len(os.listdir(face_FOLDER))}\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#For each chunk of the face data, we create new balanced data arrays that have 50:50 real and fake data\n",
    "for n in range(chunks):\n",
    "    test= np.load('data/dfdc_'+str(dataset)+'/tr_faces_'+str(dataset)+'_'+str(n)+'.npy')#, allow_pickle = True)\n",
    "    test_label= np.load('data/dfdc_'+str(dataset)+'/tr_labs_'+str(dataset)+'_'+str(n)+'.npy', allow_pickle = True)\n",
    "    real_index = np.where(test_label == 1.)\n",
    "    fake_index = np.where(test_label == 0.)\n",
    "    a =fake_index[0].tolist()\n",
    "    real = test[real_index]\n",
    "    idx = random.sample(a,len(real_index[0]))  #select a random set of fake data that has the same length for balance \n",
    "    fake = test[idx]\n",
    "    X = []\n",
    "    X_labels = []\n",
    "    for i in range(len(real)):\n",
    "        X.append(fake[i])\n",
    "        X.append(real[i])\n",
    "        X_labels.append(0.)\n",
    "        X_labels.append(1.)\n",
    "    faces = np.asarray(X)\n",
    "    labs = np.asarray(X_labels)\n",
    "    np.save(os.path.join(DATA_FOLDER, \"balanced\",'tr_faces_'+str(dataset)+'_'+str(n)+'.npy'), faces)\n",
    "    np.save(os.path.join(DATA_FOLDER, \"balanced\",'tr_labs_'+str(dataset)+'_'+str(n)+'.npy'), labs)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### iv. Saving Data as images for Keras datagen.flow_from_directory method"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "As we are training our neural network at this point, we realized that training on balanced data was good, yet the data was still not shuffled. The segmented data could lead to fitting for irrelevant features, such as the network learning the few actors in each data chunk. We adapted to Keras preprocessing library's datagen method, which pulls from pictures stored in a hierachy where the folder names are the labels  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# move through every file in the balanced folder\n",
    "\n",
    "# for dfdc_27, there were 24 chunks\n",
    "# for dfdc_14, there were 25 chunks\n",
    "# for dfdc_46, there were 22 chunks\n",
    "# for dfdc_13, there were 36 chunks \n",
    "# for dfdc_47, there were 24 chunks \n",
    "\n",
    "# We use data/aug/segregated_data/MIX_1 for train, MIX_2 for val, MIX_3 for test\n",
    "# The ratio is roughly 70:15:15 \n",
    "\n",
    "\n",
    "A =47;                  #folder number \n",
    "for B in range(24):     #number of chunks \n",
    "    chunk = np.load('data/balanced/tr_faces_'+str(A)+'_'+str(B)+'.npy', allow_pickle = True)\n",
    "    label = np.load('data/balanced/tr_labs_'+str(A)+'_'+str(B)+'.npy', allow_pickle = True)\n",
    "    #for array in each chunk, open each array, save as image, randomly choose a test/train/val folder to save to\n",
    "    for c in range(len(chunk)):\n",
    "        #face = chunk[c]*255.\n",
    "        choice = np.random.choice([1,1,1,1,1,1,1,1,1,1,2,2,3,3])\n",
    "        cv2.imwrite('data/aug/segregated_data/MIX_'+str(choice)+'/'+str(int(label[c]))+'/image_'+str(A)+'_'+str(B)+'_'+str(c)+'.png', chunk[c])"
   ]
  }
 ],
 "metadata": {
  "colab": {
   "collapsed_sections": [],
   "name": "low-ratings-cnn_project_code.ipynb",
   "provenance": []
  },
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 1
}
